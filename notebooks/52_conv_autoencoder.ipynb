{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder\n",
    "\n",
    "Yeah, I'm apparently actually doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure is roughly as follows.\n",
    "\n",
    "- Convolutional layer\n",
    "- Symmetric(!!!) activation layer\n",
    "- Max pooling layer\n",
    "- Dropout layer\n",
    "- Flatten layer\n",
    "- Dense layer\n",
    "- Symmetric activation layer\n",
    "- Unflatten layer\n",
    "- Unpool layer\n",
    "- Deconvolutional layer\n",
    "- Symmetric activation layer\n",
    "\n",
    "Inspiration from https://github.com/mikesj-public/convolutional_autoencoder/blob/master/mnist_conv_autoencode.py and https://github.com/nanopony/keras-convautoencoder/blob/master/conv_autoencoder.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up the dataset I put up on Zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py, numpy\n",
    "\n",
    "with h5py.File('../data/dataset.h5', 'r') as f:\n",
    "    features = f['features'][:, :32 * 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build an autoencoder..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras, \\\n",
    "        keras.layers, \\\n",
    "        keras.layers.core as core, \\\n",
    "        keras.layers.convolutional as conv, \\\n",
    "        keras.models as models\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "n_filters = 32\n",
    "conv_size = 5\n",
    "pool_size = 2\n",
    "dropout = 0.25\n",
    "patch_size = 32\n",
    "conv_out_size = (patch_size - conv_size) // pool_size + 1\n",
    "hidden = n_filters * conv_out_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sum(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Sum, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return x.sum(axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0],) + input_shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Encoder.\n",
    "model.add(conv.Convolution2D(n_filters, conv_size, conv_size,\n",
    "                             border_mode='valid',\n",
    "                             input_shape=(1, patch_size, patch_size)))\n",
    "model.add(core.Activation('tanh'))\n",
    "model.add(conv.MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(core.Dropout(dropout))\n",
    "model.add(core.Flatten())\n",
    "\n",
    "# Dense.\n",
    "# model.add(core.Dense(n_filters * conv_out_size * conv_out_size))\n",
    "# model.add(core.Activation('tanh'))\n",
    "\n",
    "# Decoder.\n",
    "model.add(core.Reshape((n_filters, conv_out_size, conv_out_size)))\n",
    "model.add(conv.UpSampling2D(size=(pool_size, pool_size)))\n",
    "model.add(conv.ZeroPadding2D(padding=(conv_size - 1, conv_size - 1)))\n",
    "deconv = conv.Convolution2D(n_filters, conv_size, conv_size,\n",
    "                            border_mode='valid')\n",
    "model.add(deconv)\n",
    "model.add(Sum())\n",
    "\n",
    "model.compile(loss='mse', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 480/1000 [=============>................] - ETA: 25s - loss: 0.5349"
     ]
    }
   ],
   "source": [
    "images = features.reshape((-1, patch_size, patch_size))\n",
    "model.fit(images[:1000].reshape((-1, 1, patch_size, patch_size)), images[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
