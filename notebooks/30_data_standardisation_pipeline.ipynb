{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardisation Pipeline\n",
    "\n",
    "In this notebook, I detail the process of importing data into `crowdastro`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data sources\n",
    "\n",
    "The input data sources are:\n",
    "\n",
    "- Radio Galaxy Zoo\n",
    "    - Subjects (`radio_subjects.json`)\n",
    "    - Classifications (`radio_classifications.json`)\n",
    "- ATLAS\n",
    "    - Catalogue (`ATLASDR3_cmpcat_23July2015.dat`)\n",
    "    - FITS images of the radio sky (`cdfs` & `elais`)\n",
    "- SPITZER\n",
    "    - SWIRE Catalogue (`SWIRE3_CDFS_cat_IRAC24_21Dec05.tbl`)\n",
    "    - FITS images of the infrared sky (`cdfs` & `elais`)\n",
    "\n",
    "Paths to these should be specified in `crowdastro.json`. Radio Galaxy Zoo data should be imported into a database in MongoDB, specified by `radio_galaxy_zoo_db` in `crowdastro.json`. Following is an example `crowdastro.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data_sources\": {\n",
    "        \"atlas_catalogue\": \"data/ATLASDR3_cmpcat_23July2015.dat\",\n",
    "        \"cdfs_fits\": \"data/cdfs\",\n",
    "        \"elais_s1_fits\": \"data/elais\",\n",
    "        \"radio_galaxy_zoo_db\": \"radio\",\n",
    "        \"swire_catalogue\": \"data/SWIRE3_CDFS_cat_IRAC24_21Dec05.tbl\"\n",
    "    },\n",
    "\n",
    "    \"mongo\": {\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 27017\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output data format\n",
    "\n",
    "The input data is converted into the output data by this pipeline. There are two output files for the training data and two output files for the testing data. The files are `rgz_atlas_data_{test,train}.h5` and `rgz_atlas_data_{test,train}.csv`. The partitioning ratio is specified in `crowdastro.json` as `test_size`.\n",
    "\n",
    "The `.h5` files contain numeric data, including all FITS images (both radio and infrared), classifications, and subject metadata. The structure is as follows, with datasets italicised:\n",
    "\n",
    "- `/`\n",
    "    - `atlas`\n",
    "        - `cdfs`\n",
    "            - *`catalogue`*\n",
    "            - *`images`*\n",
    "            - *`classifications`*\n",
    "            - *`positions`*\n",
    "            - *`\n",
    "        - `elais-s1`\n",
    "            - *`catalogue`*\n",
    "            - *`images`*\n",
    "            - *`classifications`*\n",
    "            - *`positions`*\n",
    "    - `swire`\n",
    "        - `cdfs`\n",
    "            - *`catalogue`*\n",
    "            - *`images`*\n",
    "            - *`classifications`*\n",
    "            - *`positions`*\n",
    "        - `elais-s1`\n",
    "            - *`catalogue`*\n",
    "            - *`images`*\n",
    "            - *`classifications`*\n",
    "            - *`positions`*\n",
    "\n",
    "I'm only using ATLAS and SWIRE for now, but this is easily generalised to FIRST and WISE or EMU and MIGHTEE.\n",
    "\n",
    "The `.csv` files contain textual data such as Zooniverse IDs. They are pretty much lookup tables; the reason for using CSV instead of HDF5 tables is partly for human readability and partly because dealing with textual data in HDF5 is unpleasant. The columns (examples parenthesised) are:\n",
    "\n",
    "- `survey` (atlas)\n",
    "- `field` (cdfs)\n",
    "- `zooniverse_id` (ARG0003r18)\n",
    "- `name` (ATLAS3_J033403.6-282423C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
