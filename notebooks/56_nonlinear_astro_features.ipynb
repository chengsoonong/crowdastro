{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Astro Features\n",
    "\n",
    "This notebook examines whether $w_1 - w_2$ and $w_2 - w_3$ are good features. There are indications that these may be correlated with whether galaxies contain AGNs. It also looks at whether the fluxes are more useful than the magnitudes, i.e., should we exponentiate the magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py, numpy, sklearn.linear_model, sklearn.cross_validation, sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File('../data/training.h5') as f:\n",
    "    raw_astro_features = f['features'][:, :4]\n",
    "    dist_features = f['features'][:, 4]\n",
    "    image_features = f['features'][:, 5:]\n",
    "    \n",
    "    w1_w2 = raw_astro_features[:, 0] - raw_astro_features[:, 1]\n",
    "    w2_w3 = raw_astro_features[:, 1] - raw_astro_features[:, 2]\n",
    "    \n",
    "    features_linear = f['features'][:]\n",
    "    features_nonlinear = numpy.hstack([\n",
    "            raw_astro_features,\n",
    "            dist_features.reshape((-1, 1)),\n",
    "            w1_w2.reshape((-1, 1)),\n",
    "            w2_w3.reshape((-1, 1)),\n",
    "            image_features,\n",
    "    ])\n",
    "    features_exp = numpy.hstack([\n",
    "            numpy.power(10, -0.4 * raw_astro_features),\n",
    "            dist_features.reshape((-1, 1)),\n",
    "            image_features,\n",
    "    ])\n",
    "    features_nlexp = numpy.hstack([\n",
    "            numpy.power(10, -0.4 * raw_astro_features),\n",
    "            numpy.power(10, -0.4 * w1_w2.reshape((-1, 1))),\n",
    "            numpy.power(10, -0.4 * w2_w3.reshape((-1, 1))),\n",
    "            dist_features.reshape((-1, 1)),\n",
    "            image_features,\n",
    "    ])\n",
    "    labels = f['labels'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, t_train, t_test = sklearn.cross_validation.train_test_split(\n",
    "        numpy.arange(raw_astro_features.shape[0]), labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear features, balanced accuracy: 88.20%\n",
      "[[4114  268]\n",
      " [  78  368]]\n"
     ]
    }
   ],
   "source": [
    "lr = sklearn.linear_model.LogisticRegression(C=100.0, class_weight='balanced')\n",
    "lr.fit(features_linear[x_train], t_train)\n",
    "cm = sklearn.metrics.confusion_matrix(t_test, lr.predict(features_linear[x_test]))\n",
    "tp = cm[1, 1]\n",
    "n, p = cm.sum(axis=1)\n",
    "tn = cm[0, 0]\n",
    "ba = (tp / p + tn / n) / 2\n",
    "print('Linear features, balanced accuracy: {:.02%}'.format(ba))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear features, balanced accuracy: 88.52%\n",
      "[[4103  279]\n",
      " [  74  372]]\n"
     ]
    }
   ],
   "source": [
    "lrnl = sklearn.linear_model.LogisticRegression(C=100.0, class_weight='balanced')\n",
    "lrnl.fit(features_nonlinear[x_train], t_train)\n",
    "cm = sklearn.metrics.confusion_matrix(t_test, lrnl.predict(features_nonlinear[x_test]))\n",
    "tp = cm[1, 1]\n",
    "n, p = cm.sum(axis=1)\n",
    "tn = cm[0, 0]\n",
    "ba = (tp / p + tn / n) / 2\n",
    "print('Nonlinear features, balanced accuracy: {:.02%}'.format(ba))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So maybe they're useful features (but not very). What about the fact they're magnitudes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated features, balanced accuracy: 89.10%\n",
      "[[4124  258]\n",
      " [  71  375]]\n"
     ]
    }
   ],
   "source": [
    "lrexp = sklearn.linear_model.LogisticRegression(C=100.0, class_weight='balanced')\n",
    "lrexp.fit(features_exp[x_train], t_train)\n",
    "cm = sklearn.metrics.confusion_matrix(t_test, lrexp.predict(features_exp[x_test]))\n",
    "tp = cm[1, 1]\n",
    "n, p = cm.sum(axis=1)\n",
    "tn = cm[0, 0]\n",
    "ba = (tp / p + tn / n) / 2\n",
    "print('Exponentiated features, balanced accuracy: {:.02%}'.format(ba))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponentiated features, balanced accuracy: 89.35%\n",
      "[[4107  275]\n",
      " [  67  379]]\n"
     ]
    }
   ],
   "source": [
    "lrnlexp = sklearn.linear_model.LogisticRegression(C=100.0, class_weight='balanced')\n",
    "lrnlexp.fit(features_nlexp[x_train], t_train)\n",
    "cm = sklearn.metrics.confusion_matrix(t_test, lrnlexp.predict(features_nlexp[x_test]))\n",
    "tp = cm[1, 1]\n",
    "n, p = cm.sum(axis=1)\n",
    "tn = cm[0, 0]\n",
    "ba = (tp / p + tn / n) / 2\n",
    "print('Exponentiated features, balanced accuracy: {:.02%}'.format(ba))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are promising results, but we need to rererun this a few times with different training and testing sets to get some error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87926733193277307]\n",
      "[0.8515625]\n",
      "[0.88248424369747902]\n",
      "[0.88453584558823528]\n",
      "[0.87926733193277307, 0.88709672756497815]\n",
      "[0.8515625, 0.88978171720807331]\n",
      "[0.88248424369747902, 0.90201871711218939]\n",
      "[0.88453584558823528, 0.90356851867109755]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275, 0.89836929366341134]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616, 0.89028843970020444]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277, 0.89785600726777193]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719, 0.9004042698160345]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275, 0.89836929366341134, 0.87160312684947727]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616, 0.89028843970020444, 0.86731233971197474]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277, 0.89785600726777193, 0.90828134247386072]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719, 0.9004042698160345, 0.90953590451765631]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275, 0.89836929366341134, 0.87160312684947727, 0.87634941658782717]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616, 0.89028843970020444, 0.86731233971197474, 0.86569082308420053]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277, 0.89785600726777193, 0.90828134247386072, 0.901931251970987]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719, 0.9004042698160345, 0.90953590451765631, 0.90642144433932514]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275, 0.89836929366341134, 0.87160312684947727, 0.87634941658782717, 0.87592505060404435]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616, 0.89028843970020444, 0.86731233971197474, 0.86569082308420053, 0.87744690610655063]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277, 0.89785600726777193, 0.90828134247386072, 0.901931251970987, 0.90776139078849805]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719, 0.9004042698160345, 0.90953590451765631, 0.90642144433932514, 0.90758745067882418]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275, 0.89836929366341134, 0.87160312684947727, 0.87634941658782717, 0.87592505060404435, 0.89230593847556916]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616, 0.89028843970020444, 0.86731233971197474, 0.86569082308420053, 0.87744690610655063, 0.8868778280542986]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277, 0.89785600726777193, 0.90828134247386072, 0.901931251970987, 0.90776139078849805, 0.894419306184012]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719, 0.9004042698160345, 0.90953590451765631, 0.90642144433932514, 0.90758745067882418, 0.89259532077589532]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275, 0.89836929366341134, 0.87160312684947727, 0.87634941658782717, 0.87592505060404435, 0.89230593847556916, 0.89844451547113535]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616, 0.89028843970020444, 0.86731233971197474, 0.86569082308420053, 0.87744690610655063, 0.8868778280542986, 0.89511513933914744]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277, 0.89785600726777193, 0.90828134247386072, 0.901931251970987, 0.90776139078849805, 0.894419306184012, 0.90695059586320259]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719, 0.9004042698160345, 0.90953590451765631, 0.90642144433932514, 0.90758745067882418, 0.89259532077589532, 0.90993466812778712]\n",
      "[0.87926733193277307, 0.88709672756497815, 0.88338354869339275, 0.89836929366341134, 0.87160312684947727, 0.87634941658782717, 0.87592505060404435, 0.89230593847556916, 0.89844451547113535, 0.86800810449011045]\n",
      "[0.8515625, 0.88978171720807331, 0.87759469717527616, 0.89028843970020444, 0.86731233971197474, 0.86569082308420053, 0.87744690610655063, 0.8868778280542986, 0.89511513933914744, 0.85676049910927476]\n",
      "[0.88248424369747902, 0.90201871711218939, 0.90199786319816277, 0.89785600726777193, 0.90828134247386072, 0.901931251970987, 0.90776139078849805, 0.894419306184012, 0.90695059586320259, 0.89731786414315262]\n",
      "[0.88453584558823528, 0.90356851867109755, 0.90017429356059719, 0.9004042698160345, 0.90953590451765631, 0.90642144433932514, 0.90758745067882418, 0.89259532077589532, 0.90993466812778712, 0.89731786414315262]\n"
     ]
    }
   ],
   "source": [
    "def balanced_accuracy(lr, x_test, t_test):\n",
    "    cm = sklearn.metrics.confusion_matrix(t_test, lr.predict(x_test))\n",
    "    tp = cm[1, 1]\n",
    "    n, p = cm.sum(axis=1)\n",
    "    tn = cm[0, 0]\n",
    "    ba = (tp / p + tn / n) / 2\n",
    "    return ba\n",
    "\n",
    "def test_feature_set(features, x_train, t_train, x_test, t_test):\n",
    "    lr = sklearn.linear_model.LogisticRegression(C=100.0, class_weight='balanced')\n",
    "    lr.fit(features[x_train], t_train)\n",
    "    return balanced_accuracy(lr, features[x_test], t_test)\n",
    "\n",
    "linear_ba = []\n",
    "nonlinear_ba = []\n",
    "exp_ba = []\n",
    "nonlinear_exp_ba = []\n",
    "\n",
    "n_trials = 10\n",
    "for trial in range(n_trials):\n",
    "    print('Trial {}/{}'.format(trial + 1, n_trials))\n",
    "    x_train, x_test, t_train, t_test = sklearn.cross_validation.train_test_split(\n",
    "        numpy.arange(raw_astro_features.shape[0]), labels, test_size=0.2)\n",
    "    linear_ba.append(test_feature_set(features_linear, x_train, t_train, x_test, t_test))\n",
    "    nonlinear_ba.append(test_feature_set(features_nonlinear, x_train, t_train, x_test, t_test))\n",
    "    exp_ba.append(test_feature_set(features_exp, x_train, t_train, x_test, t_test))\n",
    "    nonlinear_exp_ba.append(test_feature_set(features_nlexp, x_train, t_train, x_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear features: (88.31 +- 1.02)%\n",
      "Nonlinear features: (87.58 +- 1.43)%\n",
      "Exponentiated features: (90.01 +- 0.73)%\n",
      "Exponentiated nonlinear features: (90.12 +- 0.77)%\n"
     ]
    }
   ],
   "source": [
    "print('Linear features: ({:.02f} +- {:.02f})%'.format(\n",
    "        numpy.mean(linear_ba) * 100, numpy.std(linear_ba) * 100))\n",
    "print('Nonlinear features: ({:.02f} +- {:.02f})%'.format(\n",
    "        numpy.mean(nonlinear_ba) * 100, numpy.std(nonlinear_ba) * 100))\n",
    "print('Exponentiated features: ({:.02f} +- {:.02f})%'.format(\n",
    "        numpy.mean(exp_ba) * 100, numpy.std(exp_ba) * 100))\n",
    "print('Exponentiated nonlinear features: ({:.02f} +- {:.02f})%'.format(\n",
    "        numpy.mean(nonlinear_exp_ba) * 100, numpy.std(nonlinear_exp_ba) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
