{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Host Queries\n",
    "\n",
    "Now that we're using SWIRE directly instead of querying Gator, we have to quickly find the potential hosts in a neighbourhood. I can think of two ways, one which is $O(n)$ and one which is $O(\\log n)$, but the former is a lot easier. How slow is it? Let's grab 1000 subjects and find all the potential hosts in the $2' \\times 2'$ neighbourhood, then average the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import numpy\n",
    "\n",
    "CROWDASTRO_H5_PATH = '../crowdastro.h5'\n",
    "CROWDASTRO_CSV_PATH = '../crowdastro.csv'\n",
    "ARCMIN = 0.0166667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016 +- 0.0004 s\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(CROWDASTRO_H5_PATH) as f_h5:\n",
    "    positions = f_h5['/swire/cdfs/catalogue'][:, :2]\n",
    "    \n",
    "    times = []\n",
    "    for i in range(1000):\n",
    "        now = time.time()\n",
    "        sx, sy = f_h5['/atlas/cdfs/positions'][i]\n",
    "\n",
    "        lt_x = positions[:, 0] <= sx + ARCMIN\n",
    "        gt_x = positions[:, 0] >= sx - ARCMIN\n",
    "        lt_y = positions[:, 1] <= sy + ARCMIN\n",
    "        gt_y = positions[:, 1] >= sy - ARCMIN\n",
    "        enclosed = numpy.all([lt_x, gt_x, lt_y, gt_y], axis=0)\n",
    "        potential_hosts = positions[enclosed]\n",
    "        total = time.time() - now\n",
    "        times.append(total)\n",
    "\n",
    "    print('{:.02} +- {:1.1} s'.format(numpy.mean(times), numpy.std(times)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try using a tree. I'll use a $k$-d tree to store SWIRE indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012 +- 0.0003 s\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(CROWDASTRO_H5_PATH) as f_h5:\n",
    "    positions = f_h5['/swire/cdfs/catalogue'][:, :2]\n",
    "    tree = scipy.spatial.KDTree(positions, leafsize=100)\n",
    "    radius = numpy.sqrt(2) * ARCMIN\n",
    "    \n",
    "    times = []\n",
    "    for i in range(1000):\n",
    "        now = time.time()\n",
    "        point = f_h5['/atlas/cdfs/positions'][i]\n",
    "\n",
    "        enclosed = tree.query_ball_point(point, radius)\n",
    "        potential_hosts = positions[enclosed]\n",
    "        \n",
    "        lt_x = potential_hosts[:, 0] <= sx + ARCMIN\n",
    "        gt_x = potential_hosts[:, 0] >= sx - ARCMIN\n",
    "        lt_y = potential_hosts[:, 1] <= sy + ARCMIN\n",
    "        gt_y = potential_hosts[:, 1] >= sy - ARCMIN\n",
    "        enclosed = numpy.all([lt_x, gt_x, lt_y, gt_y], axis=0)\n",
    "        potential_hosts = potential_hosts[enclosed]\n",
    "        \n",
    "        total = time.time() - now\n",
    "        times.append(total)\n",
    "\n",
    "    print('{:.02} +- {:1.1} s'.format(numpy.mean(times), numpy.std(times)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this measurement actually depends a *lot* on `leafsize`. Smaller values seem to be slower to some extent. I think this is because I am returning many points.\n",
    "\n",
    "I kinda prefer sklearn to scipy, so let's have a try of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00036 +- 0.0002 s\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(CROWDASTRO_H5_PATH) as f_h5:\n",
    "    positions = f_h5['/swire/cdfs/catalogue'][:, :2]\n",
    "    tree = sklearn.neighbors.KDTree(positions, leaf_size=100)\n",
    "    radius = numpy.sqrt(2) * ARCMIN\n",
    "    \n",
    "    times = []\n",
    "    for i in range(1000):\n",
    "        now = time.time()\n",
    "        point = f_h5['/atlas/cdfs/positions'][i]\n",
    "\n",
    "        (enclosed,) = tree.query_radius(point.reshape((1, -1)), r=radius)\n",
    "        potential_hosts = positions[enclosed]\n",
    "        \n",
    "        lt_x = potential_hosts[:, 0] <= sx + ARCMIN\n",
    "        gt_x = potential_hosts[:, 0] >= sx - ARCMIN\n",
    "        lt_y = potential_hosts[:, 1] <= sy + ARCMIN\n",
    "        gt_y = potential_hosts[:, 1] >= sy - ARCMIN\n",
    "        enclosed = numpy.all([lt_x, gt_x, lt_y, gt_y], axis=0)\n",
    "        potential_hosts = potential_hosts[enclosed]\n",
    "        \n",
    "        total = time.time() - now\n",
    "        times.append(total)\n",
    "\n",
    "    print('{:.02} +- {:1.1} s'.format(numpy.mean(times), numpy.std(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014 s\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(CROWDASTRO_H5_PATH) as f_h5:\n",
    "    positions = f_h5['/swire/cdfs/catalogue'][:, :2]\n",
    "    tree = sklearn.neighbors.KDTree(positions, leaf_size=20)\n",
    "    radius = numpy.sqrt(2) * ARCMIN\n",
    "    \n",
    "    now = time.time()\n",
    "    points = f_h5['/atlas/cdfs/positions'][:1000]\n",
    "\n",
    "    all_enclosed = tree.query_radius(points, r=radius)\n",
    "#     potential_hosts = positions[enclosed]\n",
    "\n",
    "#     lt_x = potential_hosts[:, 0] <= sx + ARCMIN\n",
    "#     gt_x = potential_hosts[:, 0] >= sx - ARCMIN\n",
    "#     lt_y = potential_hosts[:, 1] <= sy + ARCMIN\n",
    "#     gt_y = potential_hosts[:, 1] >= sy - ARCMIN\n",
    "#     enclosed = numpy.all([lt_x, gt_x, lt_y, gt_y], axis=0)\n",
    "#     potential_hosts = potential_hosts[enclosed]\n",
    "\n",
    "    total = time.time() - now\n",
    "\n",
    "    print('{:.06f} s'.format(total / 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if I can find a nice way to pre-process the data into a tree, then we can very quickly query that tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
