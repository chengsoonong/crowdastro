{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Experiments\n",
    "\n",
    "In this notebook, I will collate the code from the pipeline notebook in a more efficient way, and then use it to try some different classification methods and features.\n",
    "\n",
    "I'm taking a very naÃ¯ve approach to trying different classifiers &mdash; I'm just going to use whatever the scikit-learn default is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import pprint\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import scipy.linalg\n",
    "import skimage.feature\n",
    "import sklearn.cross_validation\n",
    "import sklearn.decomposition\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import sklearn.svm\n",
    "\n",
    "sys.path.insert(1, '..')\n",
    "import crowdastro.data\n",
    "import crowdastro.rgz_analysis.consensus\n",
    "import crowdastro.show\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore', UserWarning)  # astropy always raises warnings on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_annotation_signature(annotation):\n",
    "    \"\"\"Generates a unique signature from a single radio annotation.\"\"\"\n",
    "    if 'radio' not in annotation:\n",
    "        # Metadata (ignore this).\n",
    "        return None\n",
    "\n",
    "    # Having no contours is a special case; () to avoid type errors (it's special but it's still valid!)\n",
    "    if annotation['radio'] == 'No Contours':\n",
    "        return ()\n",
    "\n",
    "    # Round to fix floating point precision loss.\n",
    "    # Sort to make sure this is deterministic.\n",
    "    xmaxs = tuple(sorted([round(float(r['xmax']), 14) for r in annotation['radio'].values()]))\n",
    "    ymaxs = tuple(sorted([round(float(r['ymax']), 14) for r in annotation['radio'].values()]))\n",
    "    signature = (xmaxs, ymaxs)\n",
    "    return signature\n",
    "\n",
    "def make_classification_signature(classification):\n",
    "    \"\"\"Generates a unique signature from a complete radio classification.\"\"\"\n",
    "    classification_signature = []\n",
    "    for annotation in classification['annotations']:\n",
    "        annotation_signature = make_annotation_signature(annotation)\n",
    "        if annotation_signature is not None:\n",
    "            classification_signature.append(annotation_signature)\n",
    "\n",
    "    classification_signature = tuple(sorted(classification_signature))\n",
    "    return classification_signature\n",
    "\n",
    "def plurality_classification_signature(subject):\n",
    "    \"\"\"Finds the most-chosen radio classification signature for a subject.\"\"\"\n",
    "    n_signatures = collections.Counter()\n",
    "    \n",
    "    for classification in crowdastro.data.db.radio_classifications.find({'subject_ids': subject['_id']}):\n",
    "        classification_signature = make_classification_signature(classification)\n",
    "        n_signatures[classification_signature] += 1\n",
    "\n",
    "    return max(n_signatures, key=n_signatures.get)\n",
    "\n",
    "def number_of_radio_sources(subject):\n",
    "    \"\"\"Finds the number of radio sources in a subject, according to volunteers.\"\"\"\n",
    "    return len(plurality_classification_signature(subject))\n",
    "\n",
    "def filter_nice(subjects):\n",
    "    \"\"\"Yields nice subjects.\"\"\"\n",
    "    for subject in subjects:\n",
    "        if number_of_radio_sources(subject) == 1:\n",
    "            yield subject\n",
    "\n",
    "def atlas_subjects():\n",
    "    \"\"\"Yields complete ATLAS subjects.\"\"\"\n",
    "    return crowdastro.data.db.radio_subjects.find({'metadata.survey': 'atlas', 'state': 'complete'})\n",
    "\n",
    "def raw_training_data(subjects, radius=20):\n",
    "    \"\"\"Returns examples matrix X and targets matrix T.\n",
    "    \n",
    "    Each row of X is one example.\n",
    "    Each row of T is one target.\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ts = []\n",
    "    \n",
    "    subjects = list(subjects)  # In case this is a generator.\n",
    "    \n",
    "    for subject in subjects:\n",
    "        # Find potential hosts.\n",
    "        ir = crowdastro.data.get_ir(subject)\n",
    "        blobs = skimage.feature.blob_log(ir/255, min_sigma=5, max_sigma=15, num_sigma=10, threshold=0.00002,\n",
    "                                         overlap=0.75, log_scale=False)\n",
    "        potential_hosts = numpy.fliplr(blobs[:, :2])\n",
    "        \n",
    "        # Find the label of each host.\n",
    "        consensus = crowdastro.rgz_analysis.consensus.consensus(subject['zooniverse_id'])\n",
    "        answers = list(consensus['answer'].values())\n",
    "        \n",
    "        classifications = numpy.zeros(potential_hosts.shape[0])\n",
    "        \n",
    "        if len(answers) != 1:\n",
    "            # My plurality radio combination differs from Kyle Willett's - odd, but does happen.\n",
    "            # Haven't solved this yet, so we'll take the noise hit for now and ignore the problem.\n",
    "            logging.warning('Ignoring a subject due to unexpected number of answers ({}).'.format(len(answers)))\n",
    "            continue\n",
    "\n",
    "        if 'ir_peak' in answers[0]:\n",
    "            true_host = numpy.array(answers[0]['ir_peak']) * 200 / 500  # Magic constant from web -> fits.\n",
    "            true_host[1] = crowdastro.config.get('fits_image_height') - true_host[1]  # Clicks are flipped vertically.\n",
    "            # Find the potential host closest to the true host. This is labelled 1; all else labelled 0.\n",
    "            classifications[numpy.array([numpy.linalg.norm(diff) for diff in potential_hosts - true_host]).argmin()] = 1\n",
    "        elif 'ir' in answers[0]:\n",
    "            true_host = numpy.array(answers[0]['ir']) * 200 / 500\n",
    "            true_host[1] = crowdastro.config.get('fits_image_height') - true_host[1]  # Clicks are flipped vertically.\n",
    "            classifications[numpy.array([numpy.linalg.norm(diff) for diff in potential_hosts - true_host]).argmin()] = 1\n",
    "        else:\n",
    "            logging.warning('No click peaks found.')\n",
    "        \n",
    "        # Fetch the large image - that way, we don't need to impose artificial restrictions\n",
    "        # on the edges of the image.\n",
    "        radio = crowdastro.data.get_radio(subject, size='5x5')\n",
    "\n",
    "        # Distance from edge of large image to edge of small image.\n",
    "        border_radius = (crowdastro.config.get('fits_image_width') * 5 // 2 -\n",
    "                         crowdastro.config.get('fits_image_width')) // 2\n",
    "\n",
    "        # Get neighbourhoods around each host.\n",
    "        for (host_x, host_y), label in zip(potential_hosts, classifications):\n",
    "            host_x, host_y = int(host_x), int(host_y)\n",
    "            neighbourhood = radio[border_radius + host_x - radius : border_radius + host_x + radius,\n",
    "                                  border_radius + host_y - radius : border_radius + host_y + radius]\n",
    "            xs.append(neighbourhood.flatten())\n",
    "            ts.append(label)\n",
    "    \n",
    "    return numpy.array(xs), numpy.array(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (5).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n"
     ]
    }
   ],
   "source": [
    "N = 100  # This uses about 2.2 GB of memory. I should try and compress on-the-fly when I have some features.\n",
    "holdout = 100  # Skip + store the first holdout so we can test later on the full subjects.\n",
    "\n",
    "subjects = filter_nice(atlas_subjects())\n",
    "heldout = [s for _, s in zip(range(holdout), subjects)]\n",
    "X, T = raw_training_data(itertools.islice(subjects, N), radius=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, T_train, T_test = sklearn.cross_validation.train_test_split(X, T, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "I've already done logistic regression in the pipeline notebook, but I would like to use it as a benchmark, so I reproduce it here. I also want to see the effect of preprocessing the data with sklearn (e.g. to scale it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = sklearn.linear_model.LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X_train, T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[757, 119],\n",
      "       [  5,  11]])\n"
     ]
    }
   ],
   "source": [
    "# Raw confusion matrix.\n",
    "pprint.pprint(sklearn.metrics.confusion_matrix(T_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the actual task, i.e., clicking the image in the right spot.\n",
    "\n",
    "radius = 20\n",
    "\n",
    "def predict(subject, lr, evaluate=False, preprocessor=None):\n",
    "    # Get input data.\n",
    "    xs = []\n",
    "    ir = crowdastro.data.get_ir(subject)\n",
    "    blobs = skimage.feature.blob_log(ir/255, min_sigma=5, max_sigma=15, num_sigma=10, threshold=0.00002,\n",
    "                                     overlap=0.75, log_scale=False)\n",
    "    potential_hosts = numpy.fliplr(blobs[:, :2])\n",
    "    radio = crowdastro.data.get_radio(subject, size='5x5')\n",
    "    border_radius = (crowdastro.config.get('fits_image_width') * 5 // 2 -\n",
    "                     crowdastro.config.get('fits_image_width')) // 2\n",
    "    for host_x, host_y in potential_hosts:\n",
    "        host_x, host_y = int(host_x), int(host_y)\n",
    "        neighbourhood = radio[border_radius + host_x - radius : border_radius + host_x + radius,\n",
    "                              border_radius + host_y - radius : border_radius + host_y + radius]\n",
    "        xs.append(neighbourhood.flatten())\n",
    "\n",
    "    xs = numpy.array(xs)\n",
    "    \n",
    "    if preprocessor is None:\n",
    "        ts = lr.predict_proba(xs)\n",
    "    else:\n",
    "        ts = lr.predict_proba(preprocessor.transform(xs))\n",
    "    predicted_host = potential_hosts[ts[:, 1].argmax()]\n",
    "    \n",
    "    if not evaluate:\n",
    "        return predicted_host\n",
    "\n",
    "    # Get actual label for evaluation.\n",
    "    consensus = crowdastro.rgz_analysis.consensus.consensus(subject['zooniverse_id'])\n",
    "    answers = list(consensus['answer'].values())\n",
    "    if len(answers) != 1:\n",
    "        raise ValueError('Unexpected number of answers ({}).'.format(len(answers)))\n",
    "    if 'ir_peak' in answers[0]:\n",
    "        true_host = numpy.array(answers[0]['ir_peak']) * 200 / 500  # Magic constant from web -> fits.\n",
    "        true_host[1] = crowdastro.config.get('fits_image_height') - true_host[1]  # Clicks are flipped vertically.\n",
    "        # Find the potential host closest to the true host. This is labelled 1; all else labelled 0.\n",
    "        closest = potential_hosts[numpy.array([numpy.linalg.norm(diff) for diff in potential_hosts - true_host]).argmin()]\n",
    "    elif 'ir' in answers[0]:\n",
    "        true_host = numpy.array(answers[0]['ir']) * 200 / 500\n",
    "        true_host[1] = crowdastro.config.get('fits_image_height') - true_host[1]  # Clicks are flipped vertically.\n",
    "        closest = potential_hosts[numpy.array([numpy.linalg.norm(diff) for diff in potential_hosts - true_host]).argmin()]\n",
    "    else:\n",
    "        closest = [-99, -99]\n",
    "        logging.warning('No click peaks found.')\n",
    "    return numpy.allclose(closest, predicted_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No click peaks found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.57%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for subject in heldout:\n",
    "    try:\n",
    "        c = predict(subject, lr, evaluate=True)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    n_correct += c\n",
    "    n_total += 1\n",
    "    \n",
    "print('{:.02%}'.format(n_correct / n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[600, 276],\n",
      "       [  2,  14]])\n"
     ]
    }
   ],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler().fit(X_train)\n",
    "lr = sklearn.linear_model.LogisticRegression(class_weight='balanced')\n",
    "lr.fit(scaler.transform(X_train), T_train)\n",
    "pprint.pprint(sklearn.metrics.confusion_matrix(T_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No click peaks found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.47%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for subject in heldout:\n",
    "    try:\n",
    "        c = predict(subject, lr, evaluate=True, preprocessor=scaler)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    n_correct += c\n",
    "    n_total += 1\n",
    "    \n",
    "print('{:.02%}'.format(n_correct / n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, scaling seems to *reduce* performance. This may be due to the physical interpretation of each pixel (i.e., each pixel represents light)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = sklearn.svm.SVC(class_weight='balanced', probability=True)\n",
    "svc.fit(X_train, T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No click peaks found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.27%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for subject in heldout:\n",
    "    try:\n",
    "        c = predict(subject, svc, evaluate=True)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    n_correct += c\n",
    "    n_total += 1\n",
    "    \n",
    "print('{:.02%}'.format(n_correct / n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is considerably worse than logistic regression. It's possible that this is due to the low number of data points, but I can't increase that at the moment &mdash; I need to reconsider how I handle the data so I can avoid MemoryErrors first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = sklearn.decomposition.TruncatedSVD(n_components=200)\n",
    "svd.fit(X_train)\n",
    "\n",
    "lr = sklearn.linear_model.LogisticRegression(class_weight='balanced')\n",
    "lr.fit(svd.transform(X_train), T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No click peaks found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.51%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for subject in heldout:\n",
    "    try:\n",
    "        c = predict(subject, lr, evaluate=True, preprocessor=svd)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    n_correct += c\n",
    "    n_total += 1\n",
    "    \n",
    "print('{:.02%}'.format(n_correct / n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not too bad, and the data are many, many times smaller. We should look at the singular values matrix to see a good place to cut it off (I chose 200 really arbitrarily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEPCAYAAACzwehFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRHL6/69OnthdXbhhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24aa6a64630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svd = scipy.linalg.svd(X_train)\n",
    "U, S, V = svd\n",
    "S.sort()\n",
    "S = S[::-1]\n",
    "matplotlib.pyplot.plot(numpy.log(S))\n",
    "matplotlib.pyplot.xlabel('Number of singular values')\n",
    "matplotlib.pyplot.ylabel('Singular value')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it looks like 200 might be a good choice after all. Now I can use this information to go back and preprocess all my data &mdash; it'll be 8 times smaller, so I can fit 8 times as many data points in. But first, I'll use it to preprocess data for the polynomial kernel &mdash; I couldn't do this earlier as I would get a MemoryError."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with dimensionality reduction and polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = sklearn.decomposition.TruncatedSVD(n_components=200)\n",
    "svd.fit(X_train)\n",
    "\n",
    "poly = sklearn.preprocessing.PolynomialFeatures(2)\n",
    "poly.fit(svd.transform(X_train))\n",
    "\n",
    "lr = sklearn.linear_model.LogisticRegression(class_weight='balanced')\n",
    "lr.fit(poly.transform(svd.transform(X_train)), T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No click peaks found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.37%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "class PolySVD(object):\n",
    "    def transform(self, xs):\n",
    "        return poly.transform(svd.transform(xs))\n",
    "\n",
    "for subject in heldout:\n",
    "    try:\n",
    "        c = predict(subject, lr, evaluate=True, preprocessor=PolySVD())\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    n_correct += c\n",
    "    n_total += 1\n",
    "    \n",
    "print('{:.02%}'.format(n_correct / n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was pretty slow, and not better than linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = sklearn.ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train, T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No click peaks found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.04%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for subject in heldout:\n",
    "    try:\n",
    "        c = predict(subject, rfc, evaluate=True)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    n_correct += c\n",
    "    n_total += 1\n",
    "    \n",
    "print('{:.02%}'.format(n_correct / n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with dimensionality reduction\n",
    "\n",
    "To put more data points into SVM, I'll need to do dimensionality reduction while processing the training data &mdash; I can only hold about 100 data points in memory otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def raw_training_data_svd(subjects, radius=20):\n",
    "    \"\"\"Returns examples matrix X and targets matrix T.\n",
    "    \n",
    "    Each row of X is one example.\n",
    "    Each row of T is one target.\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ts = []\n",
    "    \n",
    "    subjects = list(subjects)  # In case this is a generator.\n",
    "    \n",
    "    for subject in subjects:\n",
    "        # Find potential hosts.\n",
    "        ir = crowdastro.data.get_ir(subject)\n",
    "        blobs = skimage.feature.blob_log(ir/255, min_sigma=5, max_sigma=15, num_sigma=10, threshold=0.00002,\n",
    "                                         overlap=0.75, log_scale=False)\n",
    "        potential_hosts = numpy.fliplr(blobs[:, :2])\n",
    "        \n",
    "        # Find the label of each host.\n",
    "        consensus = crowdastro.rgz_analysis.consensus.consensus(subject['zooniverse_id'])\n",
    "        answers = list(consensus['answer'].values())\n",
    "        \n",
    "        classifications = numpy.zeros(potential_hosts.shape[0])\n",
    "        \n",
    "        if len(answers) != 1:\n",
    "            # My plurality radio combination differs from Kyle Willett's - odd, but does happen.\n",
    "            # Haven't solved this yet, so we'll take the noise hit for now and ignore the problem.\n",
    "            logging.warning('Ignoring a subject due to unexpected number of answers ({}).'.format(len(answers)))\n",
    "            continue\n",
    "\n",
    "        if 'ir_peak' in answers[0]:\n",
    "            true_host = numpy.array(answers[0]['ir_peak']) * 200 / 500  # Magic constant from web -> fits.\n",
    "            true_host[1] = crowdastro.config.get('fits_image_height') - true_host[1]  # Clicks are flipped vertically.\n",
    "            # Find the potential host closest to the true host. This is labelled 1; all else labelled 0.\n",
    "            classifications[numpy.array([numpy.linalg.norm(diff) for diff in potential_hosts - true_host]).argmin()] = 1\n",
    "        elif 'ir' in answers[0]:\n",
    "            true_host = numpy.array(answers[0]['ir']) * 200 / 500\n",
    "            true_host[1] = crowdastro.config.get('fits_image_height') - true_host[1]  # Clicks are flipped vertically.\n",
    "            classifications[numpy.array([numpy.linalg.norm(diff) for diff in potential_hosts - true_host]).argmin()] = 1\n",
    "        else:\n",
    "            logging.warning('No click peaks found.')\n",
    "        \n",
    "        # Fetch the large image - that way, we don't need to impose artificial restrictions\n",
    "        # on the edges of the image.\n",
    "        radio = crowdastro.data.get_radio(subject, size='5x5')\n",
    "\n",
    "        # Distance from edge of large image to edge of small image.\n",
    "        border_radius = (crowdastro.config.get('fits_image_width') * 5 // 2 -\n",
    "                         crowdastro.config.get('fits_image_width')) // 2\n",
    "\n",
    "        # Get neighbourhoods around each host.\n",
    "        for (host_x, host_y), label in zip(potential_hosts, classifications):\n",
    "            host_x, host_y = int(host_x), int(host_y)\n",
    "            neighbourhood = radio[border_radius + host_x - radius : border_radius + host_x + radius,\n",
    "                                  border_radius + host_y - radius : border_radius + host_y + radius]\n",
    "            xs.append(svd.transform(numpy.array([neighbourhood.flatten()])))\n",
    "            ts.append(label)\n",
    "    \n",
    "    return numpy.array(xs), numpy.array(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (5).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (7).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (4).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (5).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (6).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (6).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (4).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (5).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (7).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (6).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (4).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (3).\n",
      "WARNING:root:Ignoring a subject due to unexpected number of answers (2).\n"
     ]
    }
   ],
   "source": [
    "N = 546 * 3 // 4\n",
    "holdout = 546 // 4  # Skip + store the first holdout so we can test later on the full subjects.\n",
    "subjects = filter_nice(atlas_subjects())\n",
    "heldout = [s for _, s in zip(range(holdout), subjects)]\n",
    "X, T = raw_training_data_svd(itertools.islice(subjects, N), radius=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, T_train, T_test = sklearn.cross_validation.train_test_split(X, T, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1, 200))\n",
    "X_test = X_test.reshape((-1, 200))\n",
    "T_train = T_train.reshape((-1, 1))\n",
    "T_test = T_test.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = sklearn.svm.SVC(class_weight='balanced', probability=True)\n",
    "svc.fit(X_train, T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No click peaks found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.01%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for subject in heldout:\n",
    "    try:\n",
    "        c = predict(subject, svc, evaluate=True, preprocessor=svd)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    n_correct += c\n",
    "    n_total += 1\n",
    "    \n",
    "print('{:.02%}'.format(n_correct / n_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
